{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f4dae7-2bba-48ad-9669-24fe63614611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0158aaac-2836-4e9d-b4e8-a70a9210c1ab",
   "metadata": {},
   "source": [
    "# Зшивання панорам\n",
    "\n",
    "Вашим завданням буде реалізація функцій і методів, які складають основні кроки в алгоритмі зшивання панорами із двох зображень. Нагадаю, що цей алгоритм в нашому випадку складається із наступних кроків.\n",
    "\n",
    "1. **\\[SIFT\\]** Екстракція ознак і ключових точок SIFT із вхідних зображень. Робимо це на ч/б зображеннях.\n",
    "2. **\\[Matching\\]** Шукаємо пари ключових точок, що співпадають.\n",
    "3. **\\[Homography Estimation\\]** Оцінюємо проєктивне перетворення із площини зображення 1 на площину зображення 2. Робимо це за допомогою RANSAC + CLS.\n",
    "4. **\\[Perspective Warp\\]** Застосовуємо проєктивне перетворення (гомографію) до першого зображення.\n",
    "5. **\\[Blending\\]** Склеюємо зображення, змішуємо частини зображень, що перетинаються.\n",
    "\n",
    "# Важливо!\n",
    "Результати на різних стадіях для порівнянь можна подивитись в папці `stitching_stages/`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53ca032-eafb-4f8b-9aa6-813d53b7aebc",
   "metadata": {},
   "source": [
    "## Вхідні зображення\n",
    "\n",
    "Ви можете використовувати будь-які зображення, із великим перетином для зшивання. Однак, із даним завданням ідуть фото Золотих Воріт, які рекомендовано використовувати для дебагінгу і тестування."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752ce05a-e743-4704-8e98-b707ac3976d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_img_rgb = cv2.imread('media/golden_gate_1.jpg')[..., ::-1]  # read and convert BGR->RGB\n",
    "left_img_gray = cv2.cvtColor(left_img_rgb, cv2.COLOR_RGB2GRAY)  # convert RGB->Gray\n",
    "\n",
    "right_img_rgb = cv2.imread('media/golden_gate_2.jpg')[..., ::-1]  # read and convert BGR->RGB\n",
    "right_img_gray = cv2.cvtColor(right_img_rgb, cv2.COLOR_RGB2GRAY)  # convert RGB->Gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daf61d7-db8f-47a4-96f8-fa5dfaa81055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_multiple_images(nrows, ncols, images, figsize=(5, 7), dpi=300):\n",
    "    \"\"\"Draw a grid of images. \"\"\"\n",
    "    assert nrows > 1 or ncols > 1\n",
    "    f = plt.figure(dpi=dpi, figsize=figsize)\n",
    "    ax = f.subplots(nrows=nrows, ncols=ncols)\n",
    "    f.tight_layout()\n",
    "    if nrows == 1:\n",
    "        ax = ax[None, ...]\n",
    "    if ncols == 1:\n",
    "        ax = ax[..., None]\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            img = images[i][j]\n",
    "            if len(img.shape) == 2 or min(img.shape) == 1:\n",
    "                ax[i, j].imshow(img, cmap='gray')\n",
    "            else:\n",
    "                ax[i, j].imshow(img)\n",
    "            ax[i, j].axis('off')\n",
    "    f.subplots_adjust(wspace=0, hspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41000ac3-414c-4fd0-b16c-1f7f5642a84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_multiple_images(\n",
    "    nrows=2, ncols=2,\n",
    "    images=[[left_img_rgb, right_img_rgb],\n",
    "            [left_img_gray, right_img_gray]]\n",
    ")\n",
    "# stitching_stages/0_input.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e30762-671e-4e99-a79a-9a54f2ef8aab",
   "metadata": {},
   "source": [
    "# Крок 1 - SIFT\n",
    "\n",
    "Екстракція ознак і ключових точок SIFT із вхідних зображень. Робимо це на ч/б (`_gray`) зображеннях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876521e7-1c15-48f6-8a0c-39d489369b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SIFT(img):\n",
    "    siftDetector = cv2.SIFT_create()\n",
    "    kp, des = siftDetector.detectAndCompute(img, None)\n",
    "    return kp, des\n",
    "\n",
    "def plot_sift(gray, rgb, kp):\n",
    "    tmp = rgb.copy()\n",
    "    img = cv2.drawKeypoints(gray, kp, tmp, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39467ce-b369-4e3e-9f6f-ef16ec20ca09",
   "metadata": {},
   "source": [
    "Використайте `SIFT` із `OpenCV` - [Посилання на документацію](https://docs.opencv.org/4.x/da/df5/tutorial_py_sift_intro.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df83f01-e6ec-4bc8-ac97-a3e4a570e04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запишіть ключові точки та дескриптори в наступні змінні!\n",
    "left_keypoints, left_descriptors = None, None\n",
    "right_keypoints, right_descriptors = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67faf003-ba71-4314-8441-9aecb2c8505c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert left_keypoints is not None and \\\n",
    "       left_descriptors is not None and \\\n",
    "       right_keypoints is not None and \\\n",
    "       right_descriptors is not None, \"Заповніть ці змінні!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6215027-491c-4c13-8c1e-0568d5d643db",
   "metadata": {},
   "source": [
    "## Візуалізуємо отримані ключові точки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8250647c-cfaa-4fd2-b8a7-38a64d9e0ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_sift_picture = cv2.drawKeypoints(\n",
    "    left_img_gray,\n",
    "    left_keypoints,\n",
    "    left_img_rgb.copy(),  # background\n",
    "    flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS\n",
    ")\n",
    "right_sift_picture = cv2.drawKeypoints(\n",
    "    right_img_gray,\n",
    "    right_keypoints,\n",
    "    right_img_rgb.copy(),  # background\n",
    "    flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS\n",
    ")\n",
    "draw_multiple_images(\n",
    "    nrows=1, ncols=2,\n",
    "    images=[[left_sift_picture, right_sift_picture]]\n",
    ")\n",
    "# stitching_stages/1_sifts.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400d350a-a117-4054-bf53-7ab214987edd",
   "metadata": {},
   "source": [
    "# Крок 2 - Matching\n",
    "\n",
    "Шукаємо пари ключових точок, що співпадають."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47a5602-09f3-4958-9b75-edf398e95d3e",
   "metadata": {},
   "source": [
    "### Відомості BFMatcher (knnMatch)\n",
    "Тепер вам потрібно використати BFMatcher і його knnMatch для реалізації матчінгу з К найближчих сусідів. Ось як він працює.\n",
    "\n",
    "Уявімо собі, що у нас є дві множини чисел - `[9, 50]` та `[10, 51, 55]`.\n",
    "Тепер поставимо собі задачу знайти пари найближчих чисел. \n",
    "`knnMatch(set1, set2, k=2)` поверне множину матчів. Кожен матч для `k=2` буде складатись із двох пар чисел - топ 1 найближчий і топ 2 найближчий. Тобто результат буде приблизно наступним.\n",
    "`[пара(9, 10), пара(9, 51)], [пара(50, 51), пара(50, 55)]`\n",
    "\n",
    "Кожна така пара є обʼєктом класу `DMatch`. В ньому є 4 поля - відстань в парі (в нашому випадку просто абсолютна різниця між числами) `distance`, індекс числа в першій множині - `queryIdx`, індекс числа (його пари) з другої множини - `trainIdx`, індекс зображення (для нас не дуже важливий зараз) `imgIdx`.\n",
    "\n",
    "Приклад використання знаходиться в клітинці нижче. Він ніяк не повʼязаний із завданням, просто слугує для пояснення інтерфейсу.\n",
    "\n",
    "#### Ви можете реалізувати матчінг з KNN самостійно, але OpenCV варіант є рекомендованим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85792e90-314d-4a82-947c-5d26e065ef5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bf = cv2.BFMatcher()\n",
    "\n",
    "set1 = np.array([9, 50], dtype=np.float32)[..., None]\n",
    "set2 = np.array([0, 51, 55], dtype=np.float32)[..., None]\n",
    "\n",
    "matches = bf.knnMatch(set1, set2, k=2)\n",
    "\n",
    "def print_dmatch(m):\n",
    "    print(\n",
    "        f\"top1_match=(distance={m.distance}\"\n",
    "        f\", queryIdx={m.queryIdx} (num={set1[m.queryIdx][0]})\"\n",
    "        f\", trainIdx={m.trainIdx} (num={set2[m.trainIdx][0]})\"\n",
    "        f\", imgIdx={m.imgIdx})\"\n",
    "    )\n",
    "\n",
    "for i_match, match in enumerate(matches):\n",
    "    print(f\"Match #{i_match}\")\n",
    "    top1_match, top2_match = match\n",
    "    print_dmatch(top1_match)\n",
    "    print_dmatch(top2_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd821ddd-9338-491b-82d3-64ee7115a2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_features(\n",
    "    left_keypoints, left_descriptors,\n",
    "    right_keypoints, right_descriptors,\n",
    "    ratio_test_threshold\n",
    "):\n",
    "    # Крок 2.1 - Використайте BFMatcher із knnMatch (OpenCV)\n",
    "    matches = None\n",
    "\n",
    "    # Крок 2.2 - Застосуйте ratio test \n",
    "    # top_1_match_distance / top_2_match_distance < ratio_test_threshold\n",
    "    filtered_matches = []\n",
    "\n",
    "    # Крок 2.3 - складіть ключові точки, що відповідають дескрипторам, які ми матчили вище.\n",
    "    # Вони лежать в left_keypoints[idx_left].pt\n",
    "    # і в right_keypoints[idx_right].pt відповідно.\n",
    "    left_keypoints_matched = []  # масив відповідних ключових точок з лівого зображення.\n",
    "    right_keypoints_matched = []  # масив відповідних ключових точок з правого зображення.\n",
    "\n",
    "    return np.array(left_keypoints_matched), np.array(right_keypoints_matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297dfdca-6d7c-49dc-969e-424df89d95b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_keypoints_matched, right_keypoints_matched = match_features(\n",
    "    left_keypoints, left_descriptors,\n",
    "    right_keypoints, right_descriptors,\n",
    "    ratio_test_threshold=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b38874-6dd3-4563-842e-3bf986a1e538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_matches(\n",
    "    left_keypoints_matched, left_img_rgb,\n",
    "    right_keypoints_matched, right_img_rgb,\n",
    "):\n",
    "    cat_img = np.concatenate((left_img_rgb, right_img_rgb), axis=1)\n",
    "    fig = plt.figure(dpi=300, figsize=(15, 17))\n",
    "    ax = fig.subplots()\n",
    "    ax.set_aspect('equal')\n",
    "    ax.imshow(cat_img)\n",
    "    \n",
    "    right_image_start_x = cat_img.shape[1] / 2\n",
    "    left_x = left_keypoints_matched[:, 0]\n",
    "    left_y = left_keypoints_matched[:, 1]\n",
    "    right_x = right_keypoints_matched[:, 0] + right_image_start_x\n",
    "    right_y = right_keypoints_matched[:, 1]\n",
    "    ax.plot([left_x, right_x], [left_y, right_y], 'r', linewidth=0.5, marker='x')\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aaae0a-3bbf-41c8-8a30-68ff5b7749f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_matches(left_keypoints_matched, left_img_rgb,\n",
    "             right_keypoints_matched, right_img_rgb)\n",
    "# stitching_stages/2_matches.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bca267-5582-46a7-9dbb-d85e9f977f51",
   "metadata": {},
   "source": [
    "# Крок 3 - Homography Estimation\n",
    "\n",
    "Оцінюємо проєктивне перетворення із площини зображення 1 на площину зображення 2. Робимо це за допомогою RANSAC + CLS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97fd9a6-697e-4e8a-9f89-dcb26886692e",
   "metadata": {},
   "source": [
    "## Теоретичні відомості \n",
    "\n",
    "Матриця гомографії (проєктивного перетворення з площини першого зображення на площину другого) виглядає наступним чином.\n",
    "\n",
    "$$\n",
    "\\textbf{H} = \\begin{bmatrix}\n",
    "h_{11} & h_{12} & h_{13} \\\\\n",
    "h_{21} & h_{22} & h_{23} \\\\\n",
    "h_{31} & h_{32} & h_{33}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Запишемо її коефіцієнти у вигляді довгого вектора.\n",
    "\n",
    "$$\n",
    "\\textbf{h} = \\begin{bmatrix}\n",
    "h_{11} \\\\ h_{12} \\\\ h_{13} \\\\\n",
    "h_{21} \\\\ h_{22} \\\\ h_{23} \\\\\n",
    "h_{31} \\\\ h_{32} \\\\ h_{33}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Нагадаю, що тепер нам потрібно розв'язувати наступну систему рівнянь. В ній, p - ключова точка лівого зображення, q - правого. N - кількість спарованих ключових точок.\n",
    "\n",
    "$$\n",
    "A \\textbf{h} = \\textbf{0}\n",
    "$$\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "0 & 0 & 0 & p^1_x & p^1_y & 1 & -q^1_y p^1_x & -q^1_y p^1_y & -q^1_y \\\\\n",
    "p^1_x & p^1_y & 1 & 0 & 0 & 0 & -q^1_x p^1_x & -q^1_x p^1_y & -q^1_x \\\\\n",
    " \\dots &  \\dots &  \\dots &  \\dots &  \\dots &  \\dots &  \\dots &  \\dots &  \\dots \\\\\n",
    "0 & 0 & 0 & p^i_x & p^i_y & 1 & -q^i_y p^i_x & -q^i_y p^i_y & -q^i_y \\\\\n",
    "p^i_x & p^i_y & 1 & 0 & 0 & 0 & -q^i_x p^i_x & -q^i_x p^i_y & -q^i_x \\\\\n",
    " \\dots &  \\dots &  \\dots &  \\dots &  \\dots &  \\dots &  \\dots &  \\dots &  \\dots \\\\\n",
    " 0 & 0 & 0 & p^N_x & p^N_y & 1 & -q^N_y p^N_x & -q^N_y p^N_y & -q^N_y \\\\\n",
    "p^N_x & p^N_y & 1 & 0 & 0 & 0 & -q^N_x p^N_x & -q^N_x p^N_y & -q^N_x \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "h_{11} \\\\ h_{12} \\\\ h_{13} \\\\\n",
    "h_{21} \\\\ h_{22} \\\\ h_{23} \\\\\n",
    "h_{31} \\\\ h_{32} \\\\ h_{33}\n",
    "\\end{bmatrix} = \\textbf{0}\n",
    "$$\n",
    "\n",
    "Ми ж переформулюємо цю задачу на задачу мінімізації (CLS):\n",
    "\n",
    "$$ \\textbf{h} = arg\\min_{\\textbf{h}} ||A\\textbf{h}||_2^2 $$\n",
    "\n",
    "Для цього можна використати модуль `np.linalg`. Погугліть (швидше), або перегляньте лекцію про оцінку параметрів камери.\n",
    "\n",
    "Зверніть увагу, матриця H має 8 ступенів свободи та 9 коефіцієнтів (проєктивні матриці еквівалентні з точністю до множника). Таким чином ми можемо нормувати матрицю по останньому коефіцієнту. В результаті, шукана матриця гомографії дорівнює:\n",
    "\n",
    "$$\n",
    "\\textbf{H} = \\begin{bmatrix}\n",
    "\\frac{h_{11}}{h_{33}} & \\frac{h_{12}}{h_{33}} & \\frac{h_{13}}{h_{33}} \\\\\n",
    "\\frac{h_{21}}{h_{33}} & \\frac{h_{22}}{h_{33}} & \\frac{h_{23}}{h_{33}} \\\\\n",
    "\\frac{h_{31}}{h_{33}} & \\frac{h_{32}}{h_{33}} & 1\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfb15de-dc41-49ec-9bb8-159ed9082926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_homography(keypoints1, keypoints2):\n",
    "    # Побудуйте матрицю A та вирішіть CLS ||Ah||->min\n",
    "    H = None\n",
    "    \n",
    "    # Нормуйте H по останньому к-ту (див відомості).\n",
    "    H = H / H[2, 2]\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8b7dc7-9fbd-433c-b472-2bf09033bbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_homography(left_keypoints_matched, right_keypoints_matched)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27943f6-0d83-4769-8195-0e5092212bd8",
   "metadata": {},
   "source": [
    "## RANSAC\n",
    "\n",
    "На жаль, ще рано використовувати цю гомографію. Причина в тому, що оцінена матриця буде достатньо чутливою до викидів, які цілком імовірні серед пар ключових точок. Тому, ми будемо використовувати RANSAC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f079a1-bc1b-4b4b-bd9d-4423eac50f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ransac(left_keypoints_matched, right_keypoints_matched, k=5, threshold=0.5, num_iters=2323):\n",
    "    num_best_inliers = 0\n",
    "\n",
    "    def sample_random_keypoints(left_keypoints_matched, right_keypoints_matched, k):\n",
    "        # Візьміть К випадкових чисел від 0 до N-1 - це\n",
    "        # і будуть індекси наших ключових точок.\n",
    "        return None\n",
    "\n",
    "    def compute_projection_error(left_keypoints, right_keypoints, H):\n",
    "        # Перевіряємо ранг матриці спочатку\n",
    "        if np.linalg.matrix_rank(H) < 3:\n",
    "            return np.inf\n",
    "\n",
    "        # Будь ласка, памʼятайте, що до ключових 2д точок треба додати 1 в 3 вимір.\n",
    "        # Таким чином [p_x, p_y] -> [p_x, p_y, 1]\n",
    "        # ------------\n",
    "        # Підрахунок похибки для пари точок p = left_keypoints[i], q = right_keypoints[i]\n",
    "        # 1. p = [p_x, p_y, 1]^T\n",
    "        # 2. p' = Hp\n",
    "        # 3. p' = [p'_x / p'_z, p'_y / p'_z]^T  (Гомогенізація)\n",
    "        # 4. error = ||p' - q||^2\n",
    "        # Поверніть масив похибок для кожної пари точок\n",
    "        # ------------\n",
    "        return None\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        # Вибрати K випадкові пари ключових точок.\n",
    "        left_keypoints_rand, right_keypoints_rand = sample_random_keypoints(\n",
    "            left_keypoints_matched, right_keypoints_matched, k=4)\n",
    "\n",
    "        # оцінюємо гомографію за цими точками\n",
    "        H = estimate_homography(left_keypoints_rand, right_keypoints_rand)\n",
    "\n",
    "        # обчисліть похибку проєктування\n",
    "        errors = compute_projection_error(left_keypoints_matched, right_keypoints_matched, H)\n",
    "        idx = np.where(errors < threshold)[0]\n",
    "        left_keypoints_inliers = left_keypoints_matched[idx]\n",
    "        right_keypoints_inliers = right_keypoints_matched[idx]\n",
    "\n",
    "        # Якщо кількість інлаєрів більше найкращої, зберігаємо її\n",
    "        num_inliers = len(left_keypoints_inliers)\n",
    "        if num_inliers > num_best_inliers:\n",
    "            left_keypoints_inliers_best = left_keypoints_inliers.copy()\n",
    "            right_keypoints_inliers_best = right_keypoints_inliers.copy()\n",
    "            num_best_inliers = num_inliers\n",
    "            best_H = H.copy()\n",
    "\n",
    "    mean_best_error = compute_projection_error(left_keypoints_matched, right_keypoints_matched, best_H).mean()\n",
    "    \n",
    "    print(f\"Кількість інлаєрів = {num_best_inliers}\")\n",
    "    print(f\"Всього точок = {len(left_keypoints_matched)}\")\n",
    "    print(f\"Гомографія = {best_H}\")\n",
    "    print(f\"Середня похибка = {mean_best_error**0.5:.4f} (пікс.)\")\n",
    "\n",
    "    return left_keypoints_inliers_best, right_keypoints_inliers_best, best_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90071481-8250-4e6a-8bca-2fbffbb793ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_keypoints_filtered, right_keypoints_filtered, H = ransac(left_keypoints_matched, right_keypoints_matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98095221-e444-4a15-8271-a96e806bd666",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_matches(left_keypoints_filtered, left_img_rgb,\n",
    "             right_keypoints_filtered, right_img_rgb)\n",
    "# stitching_stages/3_homography.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e495821-d838-4379-8eee-33745d07c375",
   "metadata": {},
   "source": [
    "# Крок 4 - Perspective Warp\n",
    "\n",
    "Застосовуємо проєктивне перетворення (гомографію) до першого зображення.\n",
    "На цьому кроці ви на самоті. Дам декілька порад.\n",
    "\n",
    "1 - Використовуйте cv2.warpPerspective.\n",
    "\n",
    "2 - Єдине, над чим доведеться попрацювати - розміри зображень, додаткова трансляція правих зображень вправо і тд.\n",
    "\n",
    "3 - Для наступного кроку застосовуйте warpPerspective не тільки до зображень, а й до альфа маски!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38cdc5a-c94f-4030-86b3-fbcfa583feae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alpha_mask(h, w):\n",
    "    i = np.arange(h)\n",
    "    j = np.arange(w)\n",
    "    j, i = np.meshgrid(j, i)\n",
    "    \n",
    "    h_band_width = 0.15\n",
    "    w_band_width = 0.35\n",
    "    \n",
    "    top_band = (i < h_band_width*h) * ((i) / (h_band_width*h) ) + (i >= h_band_width*h)\n",
    "    bot_band = (i > h-h_band_width*h) * ((h-i-1) / (h_band_width*h) ) + (i <= h-h_band_width*h) \n",
    "    \n",
    "    left_band = (j < w_band_width*w) * ((j) / (w_band_width*w) ) + (j >= w_band_width*w)\n",
    "    right_band = (j > w-w_band_width*w) * ((w-j-1) / (w_band_width*w) ) + (j <= w-w_band_width*w)\n",
    "    return top_band*bot_band*right_band*left_band"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d709a0d-1da1-427d-9ea8-6d3149d16c4c",
   "metadata": {},
   "source": [
    "## Alpha mask\n",
    "\n",
    "Альфа маска виглядає наступним чином. Вона нам буде потрібна для блендінгу. \n",
    "Просто повторюйте з масками ті самі дії, що і з відповідними зображеннями,\n",
    "потім ми їх використовуватимемо як ваги для пікселів."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a9b11f-a996-4f0f-bd0b-2029a66981ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = get_alpha_mask(*left_img_gray.shape)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf65dbc-a35b-4148-9468-6ec488d7322e",
   "metadata": {},
   "source": [
    "## Warping!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4892d0-3eec-4b23-b8d7-036854dd4de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_images(left, right, H):\n",
    "    # Convert to double and normalize. Avoid noise.\n",
    "    left = cv2.normalize(left.astype('float'), None, 0.0, 1.0, cv2.NORM_MINMAX)   \n",
    "    # Convert to double and normalize.\n",
    "    right = cv2.normalize(right.astype('float'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
    "    left_mask = get_alpha_mask(*left.shape[:2])\n",
    "    right_mask = get_alpha_mask(*right.shape[:2])\n",
    "\n",
    "    # Використайте warpPerspective для обох зображень\n",
    "    # Памʼятайте, що результовані зображення повинні лежати на \"спільній\" площині\n",
    "    # великого розміру.\n",
    "   \n",
    "    ## warped_l = cv2.warpPerspective(src=left, M=H, dsize=combined_size??)\n",
    "    ## warped_l_w = cv2.warpPerspective(src=left_mask, M=H, dsize=combined_size??)\n",
    "\n",
    "    ## warped_r = cv2.warpPerspective(src=right, M=Hr??, dsize=combined_size??)\n",
    "    ## warped_r_w = cv2.warpPerspective(src=right_mask, M=Hr??, dsize=combined_size??)\n",
    "\n",
    "    return warped_l, warped_r, warped_l_w, warped_r_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3d09a4-5b0a-4bff-aede-ce158320cef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_img_warped, right_img_warped, left_mask_warped, right_mask_warped = warp_images(\n",
    "    left_img_rgb, right_img_rgb, H)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41364a0c-1846-4941-9cde-273dfd7d6c45",
   "metadata": {},
   "source": [
    "## Візуалізуємо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc75bda-9cfe-4755-84ca-c3ecf8fcf25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_multiple_images(\n",
    "    nrows=2, ncols=2,\n",
    "    images=[[left_img_warped, right_img_warped],\n",
    "            [left_mask_warped, right_mask_warped]],\n",
    "    figsize=(20, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f7a40e-23fa-4e36-bad2-887a50b5e22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_mask = (left_mask_warped > 0)[..., None]\n",
    "resulting_image = left_img_warped * simple_mask + right_img_warped * (1 - simple_mask)\n",
    "fig = plt.figure()\n",
    "plt.imshow(resulting_image, cmap='gray');\n",
    "plt.axis('off');\n",
    "# stitching_stages/4_simple_stitching.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc76b4b-6caa-4788-99cd-805d7c6c87ff",
   "metadata": {},
   "source": [
    "# Крок 5 - Blending\n",
    "\n",
    "Як бачите, видно шви. Щоб їх прибрати, застосуємо блендінг.\n",
    "\n",
    "Склеюємо зображення, змішуємо частини зображень, що перетинаються."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac20490c-05db-453b-b83e-e9fe29bc55eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_mask_left = left_mask_warped > 0\n",
    "simple_mask_right = right_mask_warped > 0\n",
    "\n",
    "# Спочатку присвоїмо вагам, які не лежать на перетині зображень вагу 1.\n",
    "right_mask_warped[~simple_mask_left] = (right_mask_warped[~simple_mask_left] > 0).astype(float)\n",
    "left_mask_warped[~simple_mask_right] = (left_mask_warped[~simple_mask_right] > 0).astype(float)\n",
    "\n",
    "# Підрахуємо маску перетину.\n",
    "intersection_mask = simple_mask_left & simple_mask_right\n",
    "\n",
    "# Ваги будуть дорівнювати W1/(W1 + W2) та W2/(W1 + W2) відповідно.\n",
    "w_total = left_mask_warped[intersection_mask] + right_mask_warped[intersection_mask]\n",
    "left_mask_warped[intersection_mask] /= w_total\n",
    "right_mask_warped[intersection_mask] /= w_total\n",
    "\n",
    "# Накладаємо зображення із вагами.\n",
    "resulting_image = left_img_warped * left_mask_warped[..., None] + right_img_warped * right_mask_warped[..., None]\n",
    "plt.figure(dpi=300)\n",
    "plt.imshow(resulting_image, cmap='gray')\n",
    "plt.axis(\"off\");\n",
    "\n",
    "# stitching_stages/5_blending.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec5a1fd-3363-4f8b-a8c2-68d2583668fd",
   "metadata": {},
   "source": [
    "# Вітаю! Ви завершили завдання\n",
    "\n",
    "# Excellency project:\n",
    "Зшивач панорам із більш ніж двох зображень. Зшити два зображення достатньо просто, але не завжди! Не завжди точки бувають робастними, не завжди альфа-блендінг простий, зображення ще треба кропнути, а шви не завжди є лінійними! Звертайтесь, якщо вам це цікаво."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
